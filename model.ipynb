{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"model_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indexes = np.sort(np.random.choice(data.shape[0], data.shape[0]//2, replace=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = data.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col = np.r_[np.arange(0, 4), np.arange(10, 16), np.arange(4, 10), np.arange(16, 18), np.arange(27, 36), np.arange(18, 27),  np.arange(38, 40), np.arange(36, 38), np.arange(40, 42)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3, 10, 11, 12, 13, 14, 15,  4,  5,  6,  7,  8,  9, 16,\n",
       "       17, 27, 28, 29, 30, 31, 32, 33, 34, 35, 18, 19, 20, 21, 22, 23, 24,\n",
       "       25, 26, 38, 39, 36, 37, 40, 41])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surface', 'draw_size', 'tourney_level', 'tourney_date',\n",
       "       'winner_id', 'winner_seed', 'winner_entry', 'winner_hand',\n",
       "       'winner_ht', 'winner_age', 'loser_id', 'loser_seed', 'loser_entry',\n",
       "       'loser_hand', 'loser_ht', 'loser_age', 'best_of', 'minutes',\n",
       "       'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon', 'w_2ndWon',\n",
       "       'w_SvGms', 'w_bpSaved', 'w_bpFaced', 'l_ace', 'l_df', 'l_svpt',\n",
       "       'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved',\n",
       "       'l_bpFaced', 'winner_rank', 'winner_rank_points', 'loser_rank',\n",
       "       'loser_rank_points', 'year', 'rank_difference'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[indexes] = data[columns[col]].iloc[indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = np.ones(data.shape[0])\n",
    "target[indexes] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = ['winner_ht', 'loser_ht', 'w_SvGms', 'l_SvGms', 'l_df', 'w_df', 'w_bpFaced', 'l_1stWon', \n",
    "                               'l_1stIn', 'l_svpt', 'l_ace', 'w_bpSaved', 'w_1stWon', 'w_2ndWon', 'w_1stIn', 'w_svpt', 'w_ace', 'l_bpSaved', \n",
    "                               'l_bpFaced', 'l_2ndWon', 'loser_rank', 'loser_rank_points', 'winner_rank', 'winner_rank_points',\n",
    "                               'winner_age', 'loser_age']\n",
    "\n",
    "for column in columns_with_missing_values:\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[column] = imputer.fit_transform(data[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Confusion Matrix:\n",
      "[[   0 4636]\n",
      " [   0    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00    4636.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    4636.0\n",
      "   macro avg       0.00      0.00      0.00    4636.0\n",
      "weighted avg       0.00      0.00      0.00    4636.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "one_hot_cols = ['winner_entry', 'loser_entry', 'tourney_level', 'surface', 'winner_hand', 'loser_hand']\n",
    "scale_cols = ['winner_age', 'loser_age', 'winner_ht', 'loser_ht', 'minutes', 'w_ace', 'l_ace', 'w_df', 'l_df', 'w_svpt', 'l_svpt', 'w_1stIn', 'l_1stIn', \n",
    "              'w_1stWon', 'l_1stWon', 'w_2ndWon', 'l_2ndWon', 'w_SvGms', 'l_SvGms', 'w_bpSaved', 'l_bpSaved', 'w_bpFaced', 'l_bpFaced']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore'), one_hot_cols),\n",
    "        ('scaler', StandardScaler(), scale_cols),\n",
    "        # ('imputer', SimpleImputer(), scale_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Include the columns not specified in transformers\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1, random_state=42)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
